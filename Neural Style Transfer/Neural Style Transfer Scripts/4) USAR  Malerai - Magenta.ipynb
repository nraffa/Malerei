{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"4) USAR  Malerai - Magenta.ipynb","provenance":[{"file_id":"16vclEmV1eTfy29_vMV8xHz69YyepMx-o","timestamp":1622908918383}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hJfhH0L7JJ7r"},"source":["Sacado de:\n","https://www.tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization"]},{"cell_type":"code","metadata":{"id":"68D-2GCBoOYg"},"source":["#AGARRAR UNA SOLA IMAGEN CONTENIDO Y SE PUEDEN SELECCIONAR UNA O MAS IMAGENES ESTILO. LUEGO SE DESCARGAN SOLAS LAS IMAGENES\n","#EL TIEMPO QUE TARDA ES EN FUNCION DEL TAMAÑO DE IMAGEN QUE SE LE DA PARA COMPUTAR (SEA ESTILO O CONTENIDO)\n","#LA IMAGEN SALIDA VA A SER DEL MISMO TAMAÑO QUE LA DE ENTRADA (contenido) PERO CON UNA DEFINICION MENOR --> LETSENHANCE.IO\n","\n","#PONER 1 AHORA SIEMPRE, DESPUES LO HARE PARA QUE AGARRE DIRECTO DEL DRIVE\n","\n","#SE PUEDEN CARGAR HASTA 14 ESTILOS NOMAS // LIMITACIONES DEL GOOGLE COLAB"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pzctnBKtOwdsdRQKIVt2jDhIrhssEIc4"},"id":"3PXQutBRnx0F","executionInfo":{"status":"ok","timestamp":1633531656482,"user_tz":180,"elapsed":130966,"user":{"displayName":"Hans Bellucci","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03017462007910639037"}},"outputId":"23383167-08c7-4ad2-c673-3103a19229ec"},"source":["#@title Settings\n","#@markdown >Alpha == Contrast /// Beta == Brightness // f(x) -> pixels originales // g(x) -> pixels after transf.l.\n","\n","#@markdown >g(x) = α f(x) + β\n","\n","#@markdown si a = 1 & b = 0 --> no se descarga la variante (solo original)\n","\n","#@markdown >(0 sin collage, 1 con collage --> requiere 9 imagenes estilo)\n","\n","collage = 0 #@param [0,1]\n","\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import matplotlib\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","from google.colab import files\n","import PIL.Image\n","from __future__ import print_function\n","from builtins import input\n","#import cv2 as cv #OJO ACA\n","import argparse\n","\n","#drive.mount('/content/drive')\n","#!pip install spontit #SOLO HACE FALTA CORRER UNA VEZ ESTO\n","#from spontit import SpontitResource\n","#configuracion notificaciones al celular\n","#resource = SpontitResource(\"nicolas_raffa5828\", \"AWUC4HVUGE22LBE4Q4H1EACX6KBHG3NJCL0EYJFGBRNCMBK634JR52ZG0REXD7ZXABYUUPMY6QJNF4VY495P85D236QV69NOGY34\")\n","\n","ind = 0 #default en 0 > agarra la primer imagen contenido subida\n","lst = []\n","\n","model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n","\n","def load_image(img_path):\n","    img = tf.io.read_file(img_path) #leo archivo\n","    img = tf.image.decode_image(img , channels = 3) #me aseguro que tiene 3 canales (rgb)\n","    img = tf.image.convert_image_dtype(img , tf.float32) #me aseguro que tenga el formato correcto: float 32 bit\n","    img = img[tf.newaxis , :] #me aseguro que la imagen este en un array\n","    return img\n","    \n","def tensor_to_image(tensor):\n","  tensor = tensor*255\n","  tensor = np.array(tensor, dtype=np.uint8)\n","  if np.ndim(tensor)>3:\n","    assert tensor.shape[0] == 1\n","    tensor = tensor[0]\n","  return PIL.Image.fromarray(tensor)\n","\n","source = input(\"Poner 1 si se va a subir desde la computadora, 0 si va a ser desde el drive:  \")\n","\n","while not(source == \"1\" or source == \"0\")  :\n","  source = input (\"Ingreso no valido, volver a escribir: \")\n","  print(\"Respuesta valida: \" + source)\n","\n","#OPCION SI SE SUBE DESDE LA COMPU\n","if source == \"1\":\n","  print(\"SELECCIONAR IMAGENES CONTENIDO\")\n","  content_image = files.upload()\n","\n","  for fn in content_image.keys():\n","    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","     name=fn, length=len(content_image[fn])))\n","  \n","  contenidos = list(content_image.keys()) #LA IDEA IGUAL ES QUE SE HAGA DE A UNA SOLA IMAGEN CONTENIDO Y VARIAS DE ESTILO\n","\n","\n","  print(\"SELECCIONAR IMAGENES ESTILO\")\n","  style_image = files.upload()\n","  \n","  for fn in style_image.keys():\n","    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","     name=fn, length=len(style_image[fn])))\n"," \n","  estilos = list(style_image.keys())\n","\n","content_image = load_image(contenidos[ind]) #no hace falta que este dentro del for porque uso siempre la misma de contenido\n","\n","#modificar codigo para subir desde drive\n","\n","for i in range(len(estilos)):\n","  \n","  print(\"CONTENT IMAGE\")\n","  plt.imshow(np.squeeze(content_image)) #np.squeeze hace que se pueda visualizar el tensor\n","  plt.show()\n","  print(content_image.shape) #(1, 720, 1200 , 3) --> una imagen, height and width , channels\n","  \n","  style_image = load_image(estilos[i])\n","  print(\"STYLE IMAGE \" + str(i))\n","  plt.imshow(np.squeeze(style_image))\n","  plt.show()  \n","  \n","  #aplico Neural Style Transfer\n","\n","  stylized_image = model(tf.constant(content_image) , tf.constant(style_image))[0]\n","  \n","  new_image = tensor_to_image(stylized_image)\n","  \n","\n","  #new_image = np.zeros(np.squeeze(stylized_image).shape, np.squeeze(stylized_image).dtype)\n","\n","  alpha = 1.0 # Simple contrast control\n","  beta = 0    # Simple brightness control\n","\n","  \n","  # Initialize values\n","  print(' Basic Linear Transforms ')\n","  print('-------------------------')\n","  try:\n","      alpha = 1 #@param {type:\"slider\", min:1, max:3, step:0.1} \n","      #float(input('* Enter the alpha value [1.0-3.0]: ')) \n","      beta = 0 #@param {type:\"slider\", min:0, max:100, step:5} \n","      #int(input('* Enter the beta value [0-100]: '))\n","  except ValueError:\n","      print('Error, not a number')\n","  # Do the operation new_image(i,j) = alpha*image(i,j) + beta\n","  # Instead of these 'for' loops we could have used simply:\n","  new_image = cv2.convertScaleAbs(np.float32(new_image), alpha=alpha, beta=beta)\n","  # but we wanted to show you how to access the pixels :)\n","  #Alpha // contrast and Beta // brightness\n","  #for y in range(new_image.shape[0]):\n","    #  for x in range(new_image.shape[1]):\n","         # for c in range(new_image.shape[2]):\n","              #new_image[y,x,c] = np.clip(alpha*new_image[y,x,c] + beta, 0, 255)\n","  #print('Original Image')\n","  #cv2_imshow(stylized_image)\n","  # Wait until user press some key\n","  #cv.waitKey()\n","\n","\n","  print(\"STYLIZED IMAGE\")\n","  plt.imshow(np.squeeze(stylized_image))\n","  plt.show()\n","\n","  print('NEW IMAGE')\n","  plt.imshow(np.squeeze(new_image))\n","  plt.show()  \n","\n","  file_name = contenidos[ind] + ' by ' + estilos[i] + '.jpg'\n","  tensor_to_image(stylized_image).save(file_name)\n","\n","  file_name_cv = contenidos[ind] + ' by ' + estilos[i] + ' MODIFICADA.jpg'\n","  \n","  \n","  matplotlib.image.imsave(file_name_cv, new_image)\n","  \n","  \n","\n","  #lst.append(file_name)\n","  #print(lst)\n","\n","  try:\n","    from google.colab import files\n","  except ImportError:\n","    pass\n","  else:\n","    files.download(file_name)\n","    if alpha != 1.0 or beta != 0:\n","      files.download(file_name_cv)\n","  #response_true = resource.push(\"Imagen descargandose!\", push_title = \"Malerei Cuadros\")#, expirationStamp = 5 )\n","\n","#response_true = resource.push(\"Finalizo programa\", push_title = \"Malerei Cuadros\")#, expirationStamp = 5 )\n","\n","\n","if collage == 1:\n","\n","  from PIL import Image, ImageDraw\n","  import PIL\n","  import os\n","  import os.path\n","  from PIL import Image\n","\n","  collage = Image.new(\"RGBA\", (1500,1500), color=(255,255,255,255)) #1500 x 1500\n","\n","  #f = r'C:/Users/nicor/OneDrive/Documentos/Python/Neural Style Transfer/collage test'\n","  #lst = os.listdir(f)\n","\n","  c=0\n","  for i in range(0,1500,500):\n","      for j in range(0,1500,500):\n","          file = str(lst[c])\n","          photo = Image.open(file) #Image.open(file).convert(\"RGBA\")\n","          photo = photo.resize((500,500))    #500 x 500    \n","          \n","          collage.paste(photo, (i,j))\n","          c+=1\n","\n","  plt.imshow(np.squeeze(collage))\n","  plt.show() \n","  file_name_collage = contenidos[ind] + '_collage.png'\n","  collage.save(file_name_collage)\n","  files.download(file_name_collage)\n","  #response_true = resource.push(\"Collage listo!\", push_title = \"Malerei Cuadros\")#, expirationStamp = 5 )\n","\n","  \n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}